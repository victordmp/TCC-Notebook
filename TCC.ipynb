{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victordmp/TCC-Notebook/blob/main/TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.2 in /home/victordmp/.local/lib/python3.10/site-packages (4.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install antlr4-python3-runtime==4.9.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Todas as bibliotecas e importações necessárias para execução do projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from CodeTokenizer.tokenizer import TokeNizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenização com Weka usando Regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weka_tokenizer(code):\n",
        "    delimiters_regexp = re.compile(\"[ |\\n|\\f|\\r|\\t|.|,|;|:|'|\\\"|(|)|?|!]\")\n",
        "    return list(filter(None, delimiters_regexp.split(code)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenização com Lexer da linguagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lexer_tokenizer(code):\n",
        "    TN = TokeNizer(\"Java\")\n",
        "    return TN.getTokens(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lê o código do teste e salva em uma variavel em forma de **string**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('code.java','r') as file:\n",
        "    code = \" \".join(line.rstrip() for line in file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saída weka_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['@Test', 'public', 'void', 'testHttpCode', '{', 'String', 'url', '=', 'http', '//www', 'hfut', 'edu', 'cn/ch/', 'try', '{', 'Page', 'page', '=', 'requester', 'getResponse', 'new', 'CrawlDatum', 'url', 'assertEquals', '200', 'page', 'code', '}', 'catch', 'Exception', 'e', '{', 'fail', 'e', 'toString', '}', '}']\n"
          ]
        }
      ],
      "source": [
        "print(weka_tokenizer(code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saída lexer_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANTLR runtime and generated code versions disagree: 4.9.2!=4.8\n",
            "ANTLR runtime and generated code versions disagree: 4.9.2!=4.8\n",
            "[('@', 'AT', 0, 0), ('Test', 'IDENTIFIER', 0, 1), (' ', 'WS', 0, 5), ('public', 'PUBLIC', 0, 6), (' ', 'WS', 0, 12), ('void', 'VOID', 0, 13), (' ', 'WS', 0, 17), ('testHttpCode', 'IDENTIFIER', 0, 18), ('(', 'LPAREN', 0, 30), (')', 'RPAREN', 0, 31), ('{', 'LBRACE', 0, 32), ('     ', 'WS', 0, 33), ('String', 'IDENTIFIER', 0, 38), (' ', 'WS', 0, 44), ('url', 'IDENTIFIER', 0, 45), (' ', 'WS', 0, 48), ('=', 'ASSIGN', 0, 49), (' ', 'WS', 0, 50), ('\"http://www.hfut.edu.cn/ch/\"', 'STRING_LITERAL', 0, 51), (';', 'SEMI', 0, 79), ('     ', 'WS', 0, 80), ('try', 'TRY', 0, 85), (' ', 'WS', 0, 88), ('{', 'LBRACE', 0, 89), ('         ', 'WS', 0, 90), ('Page', 'IDENTIFIER', 0, 99), (' ', 'WS', 0, 103), ('page', 'IDENTIFIER', 0, 104), (' ', 'WS', 0, 108), ('=', 'ASSIGN', 0, 109), (' ', 'WS', 0, 110), ('requester', 'IDENTIFIER', 0, 111), ('.', 'DOT', 0, 120), ('getResponse', 'IDENTIFIER', 0, 121), ('(', 'LPAREN', 0, 132), ('new', 'NEW', 0, 133), (' ', 'WS', 0, 136), ('CrawlDatum', 'IDENTIFIER', 0, 137), ('(', 'LPAREN', 0, 147), ('url', 'IDENTIFIER', 0, 148), (')', 'RPAREN', 0, 151), (')', 'RPAREN', 0, 152), (';', 'SEMI', 0, 153), ('         ', 'WS', 0, 154), ('assertEquals', 'IDENTIFIER', 0, 163), ('(', 'LPAREN', 0, 175), ('200', 'DECIMAL_LITERAL', 0, 176), (',', 'COMMA', 0, 179), (' ', 'WS', 0, 180), ('page', 'IDENTIFIER', 0, 181), ('.', 'DOT', 0, 185), ('code', 'IDENTIFIER', 0, 186), ('(', 'LPAREN', 0, 190), (')', 'RPAREN', 0, 191), (')', 'RPAREN', 0, 192), (';', 'SEMI', 0, 193), ('     ', 'WS', 0, 194), ('}', 'RBRACE', 0, 199), (' ', 'WS', 0, 200), ('catch', 'CATCH', 0, 201), (' ', 'WS', 0, 206), ('(', 'LPAREN', 0, 207), ('Exception', 'IDENTIFIER', 0, 208), (' ', 'WS', 0, 217), ('e', 'IDENTIFIER', 0, 218), (')', 'RPAREN', 0, 219), (' ', 'WS', 0, 220), ('{', 'LBRACE', 0, 221), ('         ', 'WS', 0, 222), ('fail', 'IDENTIFIER', 0, 231), ('(', 'LPAREN', 0, 235), ('e', 'IDENTIFIER', 0, 236), ('.', 'DOT', 0, 237), ('toString', 'IDENTIFIER', 0, 238), ('(', 'LPAREN', 0, 246), (')', 'RPAREN', 0, 247), (')', 'RPAREN', 0, 248), (';', 'SEMI', 0, 249), ('     ', 'WS', 0, 250), ('}', 'RBRACE', 0, 255), ('  ', 'WS', 0, 256), ('}', 'RBRACE', 0, 258)]\n"
          ]
        }
      ],
      "source": [
        "print(lexer_tokenizer(code))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
