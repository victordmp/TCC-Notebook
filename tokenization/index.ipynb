{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victordmp/TCC-Notebook/blob/main/TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "vscode": {
          "languageId": "bat"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.2 in /Users/victorpires/Library/Python/3.9/lib/python/site-packages (4.9.2)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
            "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install antlr4-python3-runtime==4.9.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Todas as bibliotecas e importações necessárias para execução do projeto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from CodeTokenizer.tokenizer import TokeNizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenização com Weka usando Regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def weka_tokenizer(code):\n",
        "    delimiters_regexp = re.compile(\"[ |\\n|\\f|\\r|\\t|.|,|;|:|'|\\\"|(|)|?|!]\")\n",
        "    return list(filter(None, delimiters_regexp.split(code)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenização com Lexer da linguagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lexer_tokenizer(code):\n",
        "    TN = TokeNizer(\"Java\")\n",
        "    return list(token[0] for token in TN.getTokens(code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lê o código do teste e salva em uma variavel em forma de **string**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('code.java','r') as file:\n",
        "    code = \" \".join(line.rstrip() for line in file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saída weka_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['@Test', 'public', 'void', 'testHttpCode', '{', 'String', 'url', '=', 'http', '//www', 'hfut', 'edu', 'cn/ch/', 'try', '{', 'Page', 'page', '=', 'requester', 'getResponse', 'new', 'CrawlDatum', 'url', 'assertEquals', '200', 'page', 'code', '}', 'catch', 'Exception', 'e', '{', 'fail', 'e', 'toString', '}', '}']\n"
          ]
        }
      ],
      "source": [
        "print(weka_tokenizer(code))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Saída lexer_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANTLR runtime and generated code versions disagree: 4.9.2!=4.8\n",
            "ANTLR runtime and generated code versions disagree: 4.9.2!=4.8\n",
            "['@', 'Test', ' ', 'public', ' ', 'void', ' ', 'testHttpCode', '(', ')', '{', '     ', 'String', ' ', 'url', ' ', '=', ' ', '\"http://www.hfut.edu.cn/ch/\"', ';', '     ', 'try', ' ', '{', '         ', 'Page', ' ', 'page', ' ', '=', ' ', 'requester', '.', 'getResponse', '(', 'new', ' ', 'CrawlDatum', '(', 'url', ')', ')', ';', '         ', 'assertEquals', '(', '200', ',', ' ', 'page', '.', 'code', '(', ')', ')', ';', '     ', '}', ' ', 'catch', ' ', '(', 'Exception', ' ', 'e', ')', ' ', '{', '         ', 'fail', '(', 'e', '.', 'toString', '(', ')', ')', ';', '     ', '}', '  ', '}']\n"
          ]
        }
      ],
      "source": [
        "print(lexer_tokenizer(code))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
